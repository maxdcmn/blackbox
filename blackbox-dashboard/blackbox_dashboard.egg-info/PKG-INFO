Metadata-Version: 2.4
Name: blackbox-dashboard
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.13
Description-Content-Type: text/markdown
Requires-Dist: fastapi>=0.124.4
Requires-Dist: requests>=2.32.5
Requires-Dist: sqlalchemy>=2.0.45
Requires-Dist: uvicorn>=0.38.0

# Blackbox VRAM Monitor Dashboard

A web-based dashboard for monitoring GPU VRAM usage with interactive graphs, timeseries data storage, and real-time analytics.

## Architecture

```
┌─────────────────┐      ┌──────────────┐      ┌──────────────┐      ┌───────────────┐
│  VRAM Source    │─────>│ Data         │─────>│  FastAPI     │<─────│  Web          │
│ (C++ Server)    │      │ Collector    │      │  Backend     │      │  Dashboard    │
│ :8080/vram      │      │ (Python)     │      │  + Database  │      │  (Browser)    │
└─────────────────┘      └──────────────┘      └──────────────┘      └───────────────┘
```

## Features

- **Real-time Monitoring**: Auto-refresh dashboard showing current GPU memory state
- **Timeseries Graphs**: Interactive charts for memory usage, processes, and fragmentation
- **Database Storage**: SQLite database storing historical data (easily upgradeable to PostgreSQL)
- **REST API**: Full RESTful API for programmatic access to metrics
- **Process Tracking**: Monitor individual processes and their memory consumption
- **Responsive UI**: Modern, gradient-styled web interface

## Quick Start

### Prerequisites

Install [uv](https://docs.astral.sh/uv/) (fast Python package installer):

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Option 1: Quick Start Script

```bash
cd blackbox-dashboard
./start-dashboard.sh
```

This will automatically install dependencies and start both the API server and data collector.

### Option 2: Manual Start

#### 1. Install Dependencies

```bash
cd blackbox-dashboard

# Using uv (recommended)
uv pip install -e .

# Or using pip
pip install -r requirements.txt
```

#### 2. Start the API Server

```bash
# Using uv
uv run python api.py

# Or directly
python api.py
```

The API server will start on `http://localhost:8001`

#### 3. Start the Data Collector

In a separate terminal:

```bash
# Using uv
uv run python data_collector.py

# Or directly
python data_collector.py
```

This will start collecting data from your VRAM source (default: `http://localhost:8080/vram`) and storing it in the database.

#### 4. Open the Dashboard

Navigate to: **http://localhost:8001/** (or http://localhost:8001/static/index.html)

You should see the dashboard with real-time graphs!

## Components

### 1. Database (`database.py`)

**Models:**
- `VRAMSnapshot`: Main timeseries data (memory stats, block counts, etc.)
- `Process`: GPU processes with memory usage
- `Thread`: Active threads with allocations
- `Block`: Memory block details
- `NsightMetric`: NVIDIA Nsight profiling metrics

**Default Location:** `~/.blackbox_vram.db` (SQLite)

**PostgreSQL Support:** Set `DATABASE_URL` environment variable:
```bash
export DATABASE_URL="postgresql://user:password@localhost/blackbox"
```

### 2. API Server (`api.py`)

FastAPI-based REST API with the following endpoints:

#### Core Endpoints

- `GET /` - Dashboard (redirects to web UI)
- `GET /api` - API information

#### Snapshot Endpoints

- `POST /api/snapshots` - Submit new VRAM snapshot
- `GET /api/snapshots` - List snapshots (paginated)
- `GET /api/snapshots/latest` - Get most recent snapshot
- `GET /api/snapshots/{id}` - Get detailed snapshot by ID
- `DELETE /api/snapshots?older_than_days=30` - Cleanup old data

#### Analytics Endpoints

- `GET /api/timeseries/{metric}?duration=3600` - Get timeseries data
  - Supported metrics: `used_bytes`, `used_percent`, `fragmentation_ratio`, `num_processes`, `num_threads`, `active_blocks`
- `GET /api/stats?duration=3600` - Get summary statistics
- `GET /api/processes?duration=3600` - Get process history

**Example:**
```bash
# Get memory usage for last hour
curl http://localhost:8001/api/timeseries/used_bytes?duration=3600

# Get latest snapshot
curl http://localhost:8001/api/snapshots/latest

# Get statistics
curl http://localhost:8001/api/stats
```

### 3. Data Collector (`data_collector.py`)

Bridges the VRAM source and the dashboard database by:
1. Fetching data from the VRAM endpoint every N seconds
2. Transforming it to match the API schema
3. Submitting it to the API for storage

**Usage:**
```bash
# Default settings (5-second interval)
python data_collector.py

# Custom URLs and interval
python data_collector.py \
  --vram-url http://localhost:8080/vram \
  --api-url http://localhost:8001/api \
  --interval 10
```

### 4. Web Dashboard (`static/`)

Modern single-page application with:
- **4 Interactive Charts** (Memory Usage, Usage %, Process Count, Fragmentation)
- **Real-time Stats Cards** (Current memory, usage%, process count, fragmentation)
- **Process List** (Active GPU processes sorted by memory usage)
- **Auto-refresh** (5s, 10s, 30s, 1m, or off)
- **Time Range Selection** (5m, 10m, 30m, 1h, 2h, 6h, 24h)

Built with:
- Chart.js for interactive graphs
- Vanilla JavaScript (no heavy frameworks)
- Responsive CSS Grid layout

## Configuration

### Environment Variables

```bash
# Database
export DATABASE_URL="sqlite:///path/to/database.db"
# or
export DATABASE_URL="postgresql://user:password@localhost/blackbox"

# API Server
export API_HOST="0.0.0.0"
export API_PORT="8001"
```

### Customization

#### Change API Port

Edit `api.py`:
```python
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)  # Change port here
```

#### Change Dashboard Refresh Interval

Edit `static/index.html`:
```html
<select id="refreshInterval">
    <option value="5000" selected>5s</option>  <!-- Change default here -->
</select>
```

## Production Deployment

### Using Uvicorn Directly

```bash
# With uv
uv run uvicorn api:app --host 0.0.0.0 --port 8001 --workers 4

# Or install globally
uvicorn api:app --host 0.0.0.0 --port 8001 --workers 4
```

### Using Gunicorn + Uvicorn

```bash
# Install gunicorn
uv pip install gunicorn

# Run
uv run gunicorn api:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8001
```

### Using Docker

Create `Dockerfile`:
```dockerfile
FROM python:3.11-slim

# Install uv
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

WORKDIR /app

# Copy project files
COPY pyproject.toml .
COPY requirements.txt .
COPY . .

# Install dependencies
RUN uv pip install --system -e .

EXPOSE 8001
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8001"]
```

Build and run:
```bash
docker build -t blackbox-dashboard .
docker run -p 8001:8001 -v ~/.blackbox_vram.db:/root/.blackbox_vram.db blackbox-dashboard
```

### Systemd Service

Create `/etc/systemd/system/blackbox-dashboard.service`:
```ini
[Unit]
Description=Blackbox VRAM Monitor Dashboard
After=network.target

[Service]
Type=simple
User=your-user
WorkingDirectory=/path/to/blackbox-dashboard
ExecStart=/usr/bin/python3 /path/to/blackbox-dashboard/api.py
Restart=always

[Install]
WantedBy=multi-user.target
```

Create `/etc/systemd/system/blackbox-collector.service`:
```ini
[Unit]
Description=Blackbox VRAM Data Collector
After=network.target blackbox-dashboard.service

[Service]
Type=simple
User=your-user
WorkingDirectory=/path/to/blackbox-dashboard
ExecStart=/usr/bin/python3 /path/to/blackbox-dashboard/data_collector.py
Restart=always

[Install]
WantedBy=multi-user.target
```

Enable and start:
```bash
sudo systemctl enable blackbox-dashboard blackbox-collector
sudo systemctl start blackbox-dashboard blackbox-collector
```

## Database Management

### View Database Stats

```bash
sqlite3 ~/.blackbox_vram.db "SELECT COUNT(*) FROM vram_snapshots;"
```

### Cleanup Old Data

```bash
# Via API
curl -X DELETE "http://localhost:8001/api/snapshots?older_than_days=30"

# Via SQL
sqlite3 ~/.blackbox_vram.db "DELETE FROM vram_snapshots WHERE timestamp < datetime('now', '-30 days');"
```

### Export to CSV

```bash
# Using SQLite
sqlite3 -header -csv ~/.blackbox_vram.db \
  "SELECT timestamp, used_bytes, used_percent, num_processes FROM vram_snapshots;" \
  > export.csv
```

### Backup Database

```bash
# SQLite
cp ~/.blackbox_vram.db ~/.blackbox_vram_backup.db

# PostgreSQL
pg_dump blackbox > blackbox_backup.sql
```

## Troubleshooting

### Dashboard shows "No data available"

1. Check if data collector is running:
   ```bash
   ps aux | grep data_collector.py
   ```

2. Check if API server is running:
   ```bash
   curl http://localhost:8001/api/snapshots/latest
   ```

3. Check database has data:
   ```bash
   sqlite3 ~/.blackbox_vram.db "SELECT COUNT(*) FROM vram_snapshots;"
   ```

### Data collector fails to fetch VRAM data

1. Verify VRAM source is running:
   ```bash
   curl http://localhost:8080/vram
   ```

2. Check VRAM URL in data collector:
   ```bash
   python data_collector.py --vram-url http://your-server:8080/vram
   ```

### Charts not updating

1. Check browser console for errors (F12)
2. Verify API URL in `static/dashboard.js`:
   ```javascript
   const API_BASE_URL = 'http://localhost:8001/api';
   ```
3. Check CORS settings in `api.py`

## API Examples

### Submit Snapshot (Python)

```python
import requests

snapshot = {
    "total_bytes": 17179869184,
    "used_bytes": 8589934592,
    "free_bytes": 8589934592,
    "reserved_bytes": 0,
    "used_percent": 50.0,
    "active_blocks": 100,
    "free_blocks": 50,
    "atomic_allocations_bytes": 1048576,
    "fragmentation_ratio": 0.05,
    "processes": [
        {
            "pid": 1234,
            "name": "python",
            "used_bytes": 4294967296,
            "reserved_bytes": 5368709120
        }
    ],
    "threads": [],
    "blocks": [],
    "nsight_metrics": {},
    "vllm_metrics": ""
}

response = requests.post("http://localhost:8001/api/snapshots", json=snapshot)
print(response.json())
```

### Get Timeseries Data (JavaScript)

```javascript
async function getMemoryUsage() {
    const response = await fetch('http://localhost:8001/api/timeseries/used_bytes?duration=3600');
    const data = await response.json();

    data.forEach(point => {
        console.log(`${point.timestamp}: ${point.value / (1024**3)} GB`);
    });
}
```

## License

MIT

## Support

For issues and questions, please open an issue on GitHub.
